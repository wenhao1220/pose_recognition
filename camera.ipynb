{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0cd0c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "model_url = \"https://tfhub.dev/google/movenet/singlepose/lightning/4\"\n",
    "model = hub.load(model_url)\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# 定义关节点和连接线的索引\n",
    "keypoint_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "connections = [(0, 1), (0, 2), (1, 3), (2, 4), (5, 6), (6, 8), (8, 10), (5, 7),\n",
    "               (7, 9), (5, 11), (6, 12), (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)]\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 进行预处理\n",
    "    input_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    input_image = tf.image.resize(input_image, (192, 192))\n",
    "    input_image = tf.expand_dims(input_image, axis=0)\n",
    "    input_image = tf.cast(input_image, tf.int32)\n",
    "\n",
    "    # 进行姿势估计\n",
    "    results = model.signatures[\"serving_default\"](input=input_image)\n",
    "    keypoints = results['output_0'].numpy()\n",
    "\n",
    "    # 获取影像的宽度和高度\n",
    "    image_height, image_width, _ = frame.shape\n",
    "\n",
    "    # 绘制关键点\n",
    "    for i in keypoint_indices:\n",
    "        keypoint = keypoints[0][0][i]\n",
    "        x, y, score = int(keypoint[1] * image_width), int(keypoint[0] * image_height), keypoint[2]\n",
    "        if score > 0.2:\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
    "\n",
    "    # 绘制骨骼连接线\n",
    "    for connection in connections:\n",
    "        start_idx, end_idx = connection\n",
    "        start_point = keypoints[0][0][start_idx]\n",
    "        end_point = keypoints[0][0][end_idx]\n",
    "        start_x, start_y = int(start_point[1] * image_width), int(start_point[0] * image_height)\n",
    "        end_x, end_y = int(end_point[1] * image_width), int(end_point[0] * image_height)\n",
    "        if start_point[2] > 0.2 and end_point[2] > 0.2:\n",
    "            cv2.line(frame, (start_x, start_y), (end_x, end_y), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    cv2.imshow('Articulation point', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83b16f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "model_url = \"https://tfhub.dev/google/movenet/singlepose/lightning/4\"\n",
    "model = hub.load(model_url)\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# 定义关节点和连接线的索引\n",
    "keypoint_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "connections = [(0, 1), (0, 2), (1, 3), (2, 4), (5, 6), (6, 8), (8, 10), (5, 7),\n",
    "               (7, 9), (5, 11), (6, 12), (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)]\n",
    "\n",
    "def getAngle(pt1, pt2, pt3):\n",
    "    dx1 = pt2[0] - pt1[0]\n",
    "    dy1 = pt2[1] - pt1[1]\n",
    "    dx2 = pt3[0] - pt1[0]\n",
    "    dy2 = pt3[1] - pt1[1]\n",
    "    \n",
    "    angle = math.atan2(dy2, dx2) - math.atan2(dy1, dx1)\n",
    "    angle = math.degrees(angle)\n",
    "    \n",
    "    if angle < 0:\n",
    "        angle += 360\n",
    "    \n",
    "    if angle > 180:\n",
    "        angle = 360 - angle\n",
    "    \n",
    "    return angle\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 进行预处理\n",
    "    input_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    input_image = tf.image.resize(input_image, (192, 192))\n",
    "    input_image = tf.expand_dims(input_image, axis=0)\n",
    "    input_image = tf.cast(input_image, tf.int32)\n",
    "\n",
    "    # 进行姿势估计\n",
    "    results = model.signatures[\"serving_default\"](input=input_image)\n",
    "    keypoints = results['output_0'].numpy()\n",
    "\n",
    "    # 获取影像的宽度和高度\n",
    "    image_height, image_width, _ = frame.shape\n",
    "\n",
    "    # 绘制关键点\n",
    "    for i in keypoint_indices:\n",
    "        keypoint = keypoints[0][0][i]\n",
    "        x, y, score = int(keypoint[1] * image_width), int(keypoint[0] * image_height), keypoint[2]\n",
    "        if score > 0.2:\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
    "\n",
    "    # 绘制骨骼连接线\n",
    "    for connection in connections:\n",
    "        start_idx, end_idx = connection\n",
    "        start_point = keypoints[0][0][start_idx]\n",
    "        end_point = keypoints[0][0][end_idx]\n",
    "        start_x, start_y = int(start_point[1] * image_width), int(start_point[0] * image_height)\n",
    "        end_x, end_y = int(end_point[1] * image_width), int(end_point[0] * image_height)\n",
    "        if start_point[2] > 0.2 and end_point[2] > 0.2:\n",
    "            cv2.line_color = (0, 255, 0)\n",
    "            if (start_idx == 5 and end_idx == 7) or (start_idx == 7 and end_idx == 9):\n",
    "                angle = getAngle(keypoints[0][0][7], keypoints[0][0][5], keypoints[0][0][9])\n",
    "                if angle > 90:\n",
    "                    cv2.line_color = (0, 0, 255)  # Change line color to red for angles greater than 90\n",
    "            cv2.line(frame, (start_x, start_y), (end_x, end_y), cv2.line_color, 2)\n",
    "\n",
    "\n",
    "    cv2.imshow('Articulation point', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d706893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(1)\n",
    "if not cap.isOpened():\n",
    "    print(\"Failed to open the camera.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c36e89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to read a frame from the camera.\n"
     ]
    }
   ],
   "source": [
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read a frame from the camera.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c57f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 創建一個攝像頭物件\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "while True:\n",
    "    # 從攝像頭讀取一幀影像\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # 顯示影像 \n",
    "    cv2.imshow('Camera', frame)\n",
    "\n",
    "    # 按下 'q' 鍵退出迴圈\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 釋放攝像頭資源並關閉視窗\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcb7de8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
